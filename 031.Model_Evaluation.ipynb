{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "In this notebook, we will test multiple model and evaluate to choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "X = pd.read_pickle('PKL/X_train.pkl')\n",
    "y = pd.read_pickle('PKL/Y_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "We will split the train data once more. It's because this is a competition dataset and we actually don't have the 'test' score result. So we will use the test set we created from the initial training set as a holdout set to actually see our performance of the final model. The final test set, which we don't have the labels for, will be used to make a prediction in the final testing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We will be utilizing mostly KNN and tree-based algorithms. We will first turn categorical features to binary dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning all categorical features to dummies \n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "# Check if training and testing sets have the same features\n",
    "if X_train.shape[1] != X_test.shape[1]:\n",
    "    print('only in train:', [x for x in X_train.columns if x not in X_test.columns])\n",
    "    print('only in test:',[x for x in X_test.columns if x not in X_train.columns])\n",
    "else: \n",
    "    print ('Good to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If they are not the same, add the column with 0s and fix the order\n",
    "# X_test[colname] = 0\n",
    "# X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance Issue\n",
    "Our dataset has high class imbalance issue. We will mostly deal with this by setting the class weight within each model, but in some cases where imbalance weight is not adequately dealt with by algorithm we test with resampled set using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Our target is multi-class with imbalance issue. To focus on the imbalance of minority classes, we will also look at the macro f1 score to capture the predictive performance for overall classes. It calculates the f1 score for each class and find the average so naturally take class imbalance into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, f1_score, accuracy_score, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "To optimize the process, I will subset features based on a few random decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_feats = X_train.columns\n",
    "len(original_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, class_weight='balanced', random_state = 23)\n",
    "etc = etc.fit(X_train, y_train)\n",
    "model = SelectFromModel(etc, prefit=True, threshold = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = model.transform(X_train)\n",
    "new_feats = original_feats[model.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_new\n",
    "X_test = X_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "Since we will be testing kNN, all feature values need to be standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test= scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out train/validation \n",
    "mod = open('PKL/new_feats.pkl', 'wb')\n",
    "pickle.dump(new_feats, mod)\n",
    "mod.close()\n",
    "\n",
    "mod = open('PKL/TRAIN_X_train.pkl', 'wb')\n",
    "pickle.dump(X_train, mod)\n",
    "mod.close()\n",
    "\n",
    "mod = open('PKL/TRAIN_X_test.pkl', 'wb')\n",
    "pickle.dump(X_test, mod)\n",
    "mod.close()\n",
    "\n",
    "mod = open('PKL/TRAIN_Y_train.pkl', 'wb')\n",
    "pickle.dump(y_train, mod)\n",
    "mod.close()\n",
    "\n",
    "mod = open('PKL/TRAIN_Y_test.pkl', 'wb')\n",
    "pickle.dump(y_test, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "new_feats = pickle.load(open('PKL/new_feats.pkl', 'rb'))\n",
    "\n",
    "X_train = pickle.load(open('PKL/TRAIN_X_train.pkl', 'rb'))\n",
    "X_test = pickle.load(open('PKL/TRAIN_X_test.pkl', 'rb'))\n",
    "y_train = pickle.load(open('PKL/TRAIN_Y_train.pkl', 'rb'))\n",
    "y_test = pickle.load(open('PKL/TRAIN_Y_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier\n",
    "We'll first create a dummy classifier as a baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.332 Test F1 score:  0.295 / Cohen Kappa:  0.001\n"
     ]
    }
   ],
   "source": [
    "dummyc = DummyClassifier(strategy = 'stratified') # using the default stratified strategy\n",
    "dummyc.fit(X_train, y_train)\n",
    "y_pred = dummyc.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "f1_test = round(f1_score(y_test, y_pred, average = 'macro'), 3)\n",
    "ck_test = round(cohen_kappa_score(y_test, y_pred), 3)\n",
    "print('Accuracy: ', accuracy, 'Test F1 score: ', f1_test, '/ Cohen Kappa: ', ck_test)\n",
    "scorer['dummy'] = (accuracy, f1_test, ck_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.54      0.33      0.41      4822\n",
      "functional needs repair       0.07      0.30      0.11       678\n",
      "         non functional       0.39      0.34      0.36      3410\n",
      "\n",
      "               accuracy                           0.33      8910\n",
      "              macro avg       0.33      0.32      0.30      8910\n",
      "           weighted avg       0.45      0.33      0.37      8910\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(dummyc, X_test, y_test, xticks_rotation = 'vertical', cmap = plt.cm.Blues)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stratified dummy classifier shows the weighted F1 score around .45 and less balanced accuracy. Dummy classifier is consistently wrong on all cases but recall for minority classes are especially bad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNearestNeighbors\n",
    "Now we will run K-Nearest Neighbors using GridSearchCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function\n",
    "Function to return weighted F1 and balanced accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_pred, text, scorer = scorer):\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "    f1_test = round(f1_score(y_test, y_pred, average = 'macro'), 3)\n",
    "    ck_test = round(cohen_kappa_score(y_test, y_pred), 3)\n",
    "    print('Accuracy: ', accuracy, 'Test F1 score: ', f1_test, '/ Cohen Kappa: ', ck_test)\n",
    "    scorer[text] = (accuracy, f1_test, ck_test)\n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal value for K using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 26.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 3} :  0.8045265348595214\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': range(1, 16, 2), # setting K\n",
    "}\n",
    "\n",
    "knc = KNeighborsClassifier(weights = 'distance') \n",
    "knc_g = GridSearchCV(knc, params, cv = 5, scoring = 'accuracy', verbose = 1, n_jobs = -1)\n",
    "knc_g.fit(X_train, y_train)\n",
    "print(knc_g.best_params_, ': ', knc_g.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.745 Test F1 score:  0.633 / Cohen Kappa:  0.541\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.80      0.79      0.80      4822\n",
      "functional needs repair       0.35      0.36      0.35       678\n",
      "         non functional       0.75      0.75      0.75      3410\n",
      "\n",
      "               accuracy                           0.75      8910\n",
      "              macro avg       0.63      0.63      0.63      8910\n",
      "           weighted avg       0.75      0.75      0.75      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN performance on the test set\n",
    "y_pred = knc_g.predict(X_test)\n",
    "scoring(y_test, y_pred, 'knn gridsearch')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Accuracy:  0.745 Test F1 score:  0.633 / Cohen Kappa:  0.541\n",
    "# Recall for functional needs repair: 0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model \n",
    "mod = open('PKL/knn_gsc.pkl', 'wb')\n",
    "pickle.dump(knc_g.best_estimator_, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "#knc_g = pickle.load(open('PKL/knn_g.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with Optuna\n",
    "Now we want to try different optimization method to make sure we have the best hyperparmeter for KNN. This time we'll use optuna to explore even more hyperparameters. We'll cap the time to what it took to be same as the time it took to complete GridSearch above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperp_KNN(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 31)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree'])\n",
    "    #leaf_size = trial.suggest_int('leaf_size', 2, 60)\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "    knc = KNeighborsClassifier(weights = 'distance', \n",
    "                             n_neighbors = n_neighbors, \n",
    "                             algorithm = algorithm, \n",
    "                             #leaf_size = leaf_size, \n",
    "                             p = p)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(knc, X_train, y_train, scoring = 'accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "# initiating the optuna study\n",
    "knn_study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# optimization process\n",
    "knn_study.optimize(find_hyperp_KNN, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the study \n",
    "mod = open('PKL/knn_study.pkl', 'wb')\n",
    "pickle.dump(knn_study, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the study\n",
    "knn_study = pickle.load(open('PKL/knn_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.754 Test F1 score:  0.644 / Cohen Kappa:  0.556\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.80      0.80      0.80      4822\n",
      "functional needs repair       0.36      0.37      0.37       678\n",
      "         non functional       0.77      0.76      0.76      3410\n",
      "\n",
      "               accuracy                           0.75      8910\n",
      "              macro avg       0.64      0.64      0.64      8910\n",
      "           weighted avg       0.75      0.75      0.75      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the best params on the test set\n",
    "knc_opt = KNeighborsClassifier(**knn_study.best_params, weights = 'distance', n_jobs = -1)\n",
    "knc_opt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knc_opt.predict(X_test)\n",
    "scoring(y_test, y_pred, 'knn optuna')\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Accuracy:  0.754 Test F1 score:  0.644 / Cohen Kappa:  0.556\n",
    "# functional needs repair recall = 0.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score for the needs repair class is still low but the overall performance and the recall for non-functional improved slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "mod = open('PKL/knc_opt_model.pkl', 'wb')\n",
    "pickle.dump(knc_opt, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_study = pickle.load(open('PKL/knc_opt_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "We will run random forest optimized by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperparam_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 700)\n",
    "    #max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\n",
    "    max_features = trial.suggest_int('max_features', 2, X_train.shape[1])\n",
    "    min_weight_fraction_leaf = trial.suggest_loguniform('min_weight_fraction_leaf', 1e-7, 0.1)\n",
    "    max_leaf_nodes= trial.suggest_int('max_leaf_nodes', 10, 200)\n",
    "    rfc = RandomForestClassifier(oob_score = True, \n",
    "                                 n_estimators = n_estimators,\n",
    "                                 #max_depth = max_depth, \n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 criterion = criterion,\n",
    "                                 class_weight = class_weight, \n",
    "                                 max_features = max_features,\n",
    "                                 min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                 max_leaf_nodes = max_leaf_nodes\n",
    "                                )\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(rfc, X_train, y_train,\n",
    "                                    scoring = 'accuracy', cv = cv, n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "#rfc_study = optuna.create_study(direction='maximize')\n",
    "rfc_study.optimize(find_hyperparam_rf, n_trials = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.745 Test F1 score:  0.648 / Cohen Kappa:  0.541\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.77      0.84      0.80      4822\n",
      "functional needs repair       0.35      0.46      0.40       678\n",
      "         non functional       0.83      0.67      0.74      3410\n",
      "\n",
      "               accuracy                           0.75      8910\n",
      "              macro avg       0.65      0.66      0.65      8910\n",
      "           weighted avg       0.76      0.75      0.75      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score = True, **rfc_study.best_params, n_jobs = -1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "scoring(y_test, y_pred_rf, 'random forest optuna')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "#Accuracy:  0.745 Test F1 score:  0.648 / Cohen Kappa:  0.541\n",
    "# functional needs repair recall = 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better performance in predicting the positive minority cases even though overall F1 score has dropped slightly. This model seems to be weighing the minority recall better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the study\n",
    "mod = open('PKL/rfc_study.pkl', 'wb')\n",
    "pickle.dump(rfc_study, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the study\n",
    "rfc_study = pickle.load(open('PKL/rfc_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "mod = open('PKL/rf_model.pkl', 'wb')\n",
    "pickle.dump(rf, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pickle.load(open('PKL/rf_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quantity_dry</th>\n",
       "      <td>0.1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_enough</th>\n",
       "      <td>0.0502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_c_other</th>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.0418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_hand pump</th>\n",
       "      <td>0.0358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_insufficient</th>\n",
       "      <td>0.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_other</th>\n",
       "      <td>0.0327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_bariadi</th>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_built_after05</th>\n",
       "      <td>0.0295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_long</th>\n",
       "      <td>0.0290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feat_importance\n",
       "quantity_dry                        0.1482\n",
       "quantity_enough                     0.0502\n",
       "extraction_type_c_other             0.0500\n",
       "longitude                           0.0418\n",
       "waterpoint_type_hand pump           0.0358\n",
       "quantity_insufficient               0.0337\n",
       "waterpoint_type_other               0.0327\n",
       "lga_bariadi                         0.0308\n",
       "year_built_after05                  0.0295\n",
       "lga_long                            0.0290"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance\n",
    "rf_feats = pd.DataFrame(rf.feature_importances_,\n",
    "                        index = new_feats,\n",
    "                        columns=['feat_importance']).sort_values('feat_importance',ascending=False)\n",
    "rf_feats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>funder_jica</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder_ded</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder_jaica</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer_rwssp</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer_ir</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder_ir</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_unknown</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer_is</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer_jaica</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_c_windmill</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feat_importance\n",
       "funder_jica                             0.0\n",
       "funder_ded                              0.0\n",
       "funder_jaica                            0.0\n",
       "installer_rwssp                         0.0\n",
       "installer_ir                            0.0\n",
       "funder_ir                               0.0\n",
       "source_unknown                          0.0\n",
       "installer_is                            0.0\n",
       "installer_jaica                         0.0\n",
       "extraction_type_c_windmill              0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feats.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Now we'll try to run XGBoost with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperparam(trial):\n",
    "    eta = trial.suggest_loguniform('eta', 0.001, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "    #min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_loguniform('subsample', 0.4, 1.0)\n",
    "    sampling_method = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.01, 1.0)\n",
    "    colsample_bylevel = trial.suggest_loguniform('colsample_bylevel', 0.01, 1.0)\n",
    "    colsample_bynode = trial.suggest_loguniform('colsample_bynode', 0.01, 1.0)\n",
    "\n",
    "    xgbc = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                             eta = eta, \n",
    "                             max_depth = max_depth, \n",
    "                             #min_child_weight = min_child_weight, \n",
    "                             subsample = subsample, \n",
    "                             #sampling_method = sampling_method, \n",
    "                             colsample_bytree = colsample_bytree, \n",
    "                             colsample_bynode = colsample_bynode, \n",
    "                             colsample_bylevel = colsample_bylevel)\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "    score = np.mean(cross_val_score(xgbc, X_train, y_train, \n",
    "                                    scoring = 'accuracy', cv = cv, \n",
    "                                    n_jobs = -1))\n",
    "    return (score)\n",
    "\n",
    "xgb_study = optuna.create_study(direction='maximize')\n",
    "xgb_study.optimize(find_hyperparam, timeout = 60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving study\n",
    "mod = open('PKL/xgb_study.pkl', 'wb')\n",
    "pickle.dump(xgb_study, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the study\n",
    "xgb_study = pickle.load(open('PKL/xgb_study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.047015847004812955,\n",
       " 'max_depth': 36,\n",
       " 'subsample': 0.4778081513429783,\n",
       " 'sampling_method': 'gradient_based',\n",
       " 'colsample_bytree': 0.415717416280942,\n",
       " 'colsample_bylevel': 0.9884376260231053,\n",
       " 'colsample_bynode': 0.20250017161748426}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ = xgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_['sampling_method'] = 'uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.792 Test F1 score:  0.69 / Cohen Kappa:  0.624\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.84      0.83      4822\n",
      "functional needs repair       0.43      0.44      0.43       678\n",
      "         non functional       0.83      0.79      0.81      3410\n",
      "\n",
      "               accuracy                           0.79      8910\n",
      "              macro avg       0.69      0.69      0.69      8910\n",
      "           weighted avg       0.79      0.79      0.79      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting and testing on the test set\n",
    "\n",
    "xgbc = xgb.XGBClassifier(**best_, verbosity=1)\n",
    "\n",
    "xgbc.fit(X_train, y_train)\n",
    "y_pred = xgbc.predict(X_test)    \n",
    "scoring(y_test, y_pred, 'xgboost')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Accuracy:  0.792 Test F1 score:  0.69 / Cohen Kappa:  0.624\n",
    "# functional needs repair recall = 0.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top majority classes are doing so much better, but the minority class recall score dropped significantly from random forest model. We'll try to oversampling the minority classes and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "mod = open('PKL/xgbc_model.pkl', 'wb')\n",
    "pickle.dump(xgbc, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc_model = pickle.load(open('PKL/xgbc_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "Now I will try to run a voting classifier using some of the above models. Since many of the models did better with with minority classes oversampled, I will use oversampled data for voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knc_study',\n",
       "                              KNeighborsClassifier(algorithm='kd_tree',\n",
       "                                                   n_jobs=-1, n_neighbors=4,\n",
       "                                                   p=1, weights='distance')),\n",
       "                             ('rf_model',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     max_features=135,\n",
       "                                                     max_leaf_nodes=200,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     min_weight_fraction_leaf=2.2193985313288622e-07,\n",
       "                                                     n_estimators=466,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     oob_score...\n",
       "                                            max_delta_step=0, max_depth=36,\n",
       "                                            min_child_weight=1, missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            objective='multi:softprob',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1,\n",
       "                                            sampling_method='uniform',\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=0.4778081513429783,\n",
       "                                            tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=1))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_c_soft = VotingClassifier(estimators = [\n",
    "                                          ('knc_study', knc_study),\n",
    "                                          ('rf_model', rf_model),\n",
    "                                          ('xgbc', xgbc)\n",
    "                                         ], \n",
    "                            voting = 'soft', \n",
    "                           n_jobs = -1)\n",
    "voting_c_soft.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.789 Test F1 score:  0.685 / Cohen Kappa:  0.619\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.84      0.83      4822\n",
      "functional needs repair       0.42      0.42      0.42       678\n",
      "         non functional       0.82      0.79      0.80      3410\n",
      "\n",
      "               accuracy                           0.79      8910\n",
      "              macro avg       0.69      0.68      0.69      8910\n",
      "           weighted avg       0.79      0.79      0.79      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_c_soft.predict(X_test)    \n",
    "scoring(y_test, y_pred, 'voting')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Accuracy:  0.789 Test F1 score:  0.685 / Cohen Kappa:  0.619\n",
    "# functional needs repair recall = 0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "mod = open('PKL/voting_c_soft.pkl', 'wb')\n",
    "pickle.dump(voting_c_soft, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "#voting_c_soft = pickle.load(open('PKL/voting_c_soft.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knc_study',\n",
       "                              KNeighborsClassifier(algorithm='kd_tree',\n",
       "                                                   n_jobs=-1, n_neighbors=4,\n",
       "                                                   p=1, weights='distance')),\n",
       "                             ('rf_model',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     max_features=135,\n",
       "                                                     max_leaf_nodes=200,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     min_weight_fraction_leaf=2.2193985313288622e-07,\n",
       "                                                     n_estimators=466,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     oob_score...\n",
       "                                            learning_rate=0.0470158458,\n",
       "                                            max_delta_step=0, max_depth=36,\n",
       "                                            min_child_weight=1, missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            objective='multi:softprob',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1,\n",
       "                                            sampling_method='uniform',\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=0.4778081513429783,\n",
       "                                            tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=1))],\n",
       "                 n_jobs=-1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_c_hard = VotingClassifier(estimators = [\n",
    "                                          ('knc_study', knc_study),\n",
    "                                          ('rf_model', rf_model),\n",
    "                                          ('xgbc', xgbc)\n",
    "                                         ], \n",
    "                            voting = 'hard', \n",
    "                           n_jobs = -1)\n",
    "voting_c_hard.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.789 Test F1 score:  0.686 / Cohen Kappa:  0.617\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.85      0.83      4822\n",
      "functional needs repair       0.42      0.42      0.42       678\n",
      "         non functional       0.84      0.77      0.80      3410\n",
      "\n",
      "               accuracy                           0.79      8910\n",
      "              macro avg       0.69      0.68      0.69      8910\n",
      "           weighted avg       0.79      0.79      0.79      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_c_hard.predict(X_test)    \n",
    "scoring(y_test, y_pred, 'voting')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Test F1 score:  0.77 / Test Accuracy:  0.671\n",
    "# functional needs repair recall = 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "mod = open('PKL/voting_c_hard.pkl', 'wb')\n",
    "pickle.dump(voting_c_hard, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "#voting_c_hard = pickle.load(open('PKL/voting_c_hard.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "Separately I'll take a look at feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.721 Test F1 score:  0.609 / Cohen Kappa:  0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dummy': (0.33, 0.294, -0.006),\n",
       " 'knn optuna': (0.752, 0.641, 0.553),\n",
       " 'random forest optuna': (0.739, 0.64, 0.528),\n",
       " 'xgboost': (0.776, 0.679, 0.595),\n",
       " 'voting': (0.789, 0.688, 0.618),\n",
       " 'SGDC': (0.721, 0.609, 0.5)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC = SGDClassifier(loss = 'log', penalty='elasticnet', \n",
    "                     max_iter=1000, tol=1e-3)\n",
    "SGDC.fit(X_train, y_train)\n",
    "y_pred = SGDC.predict(X_test)\n",
    "scoring(y_test, y_pred, 'SGDC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance = pd.DataFrame(SGDC.coef_.T, columns = SGDC.classes_, index = new_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functional</th>\n",
       "      <th>functional needs repair</th>\n",
       "      <th>non functional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zero_gps_height</th>\n",
       "      <td>-0.1149</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>-0.5102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_c_gravity</th>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>-0.5590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_kigoma</th>\n",
       "      <td>-0.1515</td>\n",
       "      <td>0.4531</td>\n",
       "      <td>-0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_singida</th>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>-0.8397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gps_height</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4161</td>\n",
       "      <td>-0.2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_morogoro</th>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>-0.3351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code_1</th>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>-0.3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_bukombe</th>\n",
       "      <td>-0.0472</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>-0.1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga_bariadi</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_c_submersible</th>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.2924</td>\n",
       "      <td>-0.3025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               functional  functional needs repair  \\\n",
       "zero_gps_height                   -0.1149                   0.7935   \n",
       "extraction_type_c_gravity          1.1832                   0.7132   \n",
       "region_kigoma                     -0.1515                   0.4531   \n",
       "region_singida                     0.2190                   0.4333   \n",
       "gps_height                         0.0000                   0.4161   \n",
       "region_morogoro                    0.4695                   0.4074   \n",
       "district_code_1                    0.3417                   0.3743   \n",
       "lga_bukombe                       -0.0472                   0.3176   \n",
       "lga_bariadi                        0.0000                   0.2991   \n",
       "extraction_type_c_submersible      0.6848                   0.2924   \n",
       "\n",
       "                               non functional  \n",
       "zero_gps_height                       -0.5102  \n",
       "extraction_type_c_gravity             -0.5590  \n",
       "region_kigoma                         -0.1545  \n",
       "region_singida                        -0.8397  \n",
       "gps_height                            -0.2863  \n",
       "region_morogoro                       -0.3351  \n",
       "district_code_1                       -0.3276  \n",
       "lga_bukombe                           -0.1185  \n",
       "lga_bariadi                            0.0000  \n",
       "extraction_type_c_submersible         -0.3025  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance.sort_values(by = 'functional needs repair', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
